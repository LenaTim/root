{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CNN.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPrkMQTo6Vaor9VuEW0IV1C"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"5mBgjlFeI-GZ","colab_type":"code","colab":{}},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from google.colab import drive\n","import pickle\n","\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import f1_score\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","import torchvision\n","import torchvision.transforms as transforms"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kIlYzbpYZXLW","colab_type":"text"},"source":["## Create DataLoader"]},{"cell_type":"code","metadata":{"id":"ygJo2MKUJYsM","colab_type":"code","outputId":"6433c672-800a-4753-9e4a-6a05409b4d73","executionInfo":{"status":"ok","timestamp":1589445359413,"user_tz":-180,"elapsed":181229,"user":{"displayName":"Elena Timofeeva","photoUrl":"","userId":"07958490506212570356"}},"colab":{"base_uri":"https://localhost:8080/","height":125}},"source":["drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nxpy7CTRJrAk","colab_type":"code","colab":{}},"source":["def load_pkl_data():\n","  X = pickle.load(open('drive/My Drive/Audio analytics/pickle/X_train_log_mel.pkl', 'rb'))\n","  y = pickle.load(open('drive/My Drive/Audio analytics/pickle/y_train_log_mel.pkl', 'rb'))\n","  X_val = pickle.load(open('drive/My Drive/Audio analytics/pickle/X_test_log_mel.pkl', 'rb'))\n","\n","  return X, y, X_val"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"577-aEXBZe7Q","colab_type":"code","colab":{}},"source":["def prepare_shape(feature):\n","  tmp = feature\n","  N = 128\n","  while tmp.shape[1] < N:\n","    tmp = np.hstack((tmp, tmp))\n","  tmp = tmp[np.newaxis, :, :N]\n","  return tmp"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SC2Nbhu9aULP","colab_type":"code","colab":{}},"source":["class dataset(Dataset):\n","  def __init__(self, x, y=None):\n","    # Random shift\n","    shift = np.random.randint(x.shape[1])\n","    self.x = np.roll(x, shift, axis=1)\n","    #self.x = x\n","    self.y = y\n","    \n","  def __len__(self):\n","    return len(self.x)\n","\n","  def __getitem__(self, idx):\n","    if self.y is not None:\n","        return self.x[idx], self.y[idx]\n","    return self.x[idx]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zSYawEfpahFK","colab_type":"code","colab":{}},"source":["X, y, X_val = load_pkl_data()\n","\n","le = LabelEncoder()\n","le.fit(y)\n","y = le.transform(y)\n","classes = le.classes_\n","num_classes = len(le.classes_)\n","\n","X = np.asarray([prepare_shape(x) for x in X])\n","X_val = np.asarray([prepare_shape(x) for x in X_val])\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zcpUCu81aqup","colab_type":"code","outputId":"3c538e5e-cbaf-4d1a-f136-93f21ff415fa","executionInfo":{"status":"ok","timestamp":1589445386830,"user_tz":-180,"elapsed":566,"user":{"displayName":"Elena Timofeeva","photoUrl":"","userId":"07958490506212570356"}},"colab":{"base_uri":"https://localhost:8080/","height":141}},"source":["print('Number of class:', num_classes)\n","print('Train Set\\nX:', X_train.shape, ', y:', y_train.shape)\n","print('Test Set\\nX:', X_test.shape, ', y:', y_test.shape)\n","print('Val Set\\nX:', X_val.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Number of class: 41\n","Train Set\n","X: (4546, 1, 64, 128) , y: (4546,)\n","Test Set\n","X: (1137, 1, 64, 128) , y: (1137,)\n","Val Set\n","X: (3790, 1, 64, 128)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lGjQgXxsaJ9V","colab_type":"code","colab":{}},"source":["train_dset = dataset(X_train, y_train)\n","test_dset = dataset(X_test, y_test)\n","val_dset = dataset(X_val)\n","\n","train_loader = DataLoader(train_dset, batch_size=64, shuffle=True, num_workers=0)\n","test_loader = DataLoader(test_dset, batch_size=64, shuffle=False, num_workers=0)\n","val_loader = DataLoader(val_dset, batch_size=64, shuffle=False, num_workers=0)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r3kNt9DPZfcq","colab_type":"text"},"source":["## Models"]},{"cell_type":"code","metadata":{"id":"1hYy8UOaTCTX","colab_type":"code","colab":{}},"source":["class ConvNet(nn.Module):\n","  def __init__(self):\n","    super(ConvNet,self).__init__()\n","\n","    self.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, stride=1, padding=1)\n","    self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n","    self.conv3 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1)\n","    self.conv4 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1)\n","    self.conv5 = nn.Conv2d(in_channels=512, out_channels=256, kernel_size=3, stride=1, padding=1)\n","        \n","    self.mp = nn.MaxPool2d(kernel_size=2, stride=2)\n","    self.globalmp = nn.MaxPool2d(kernel_size=(16,32), stride=1)\n","\n","    self.dropout = nn.Dropout(p=0.3)\n","\n","    self.bn1 = nn.BatchNorm2d(num_features=64)\n","    self.bn2 = nn.BatchNorm2d(num_features=128)\n","    self.bn3 = nn.BatchNorm2d(num_features=256)\n","    self.bn4 = nn.BatchNorm2d(num_features=512)\n","    self.bn5 = nn.BatchNorm2d(num_features=256)\n","\n","    self.flat = nn.Flatten()\n","    self.fc1 = nn.Linear(256, 41)\n","        \n","  def forward(self, x):\n","    x = self.conv1(x)\n","    x = self.bn1(x)\n","    x = F.relu(x)\n","    x = self.mp(x)\n","    x = self.dropout(x)\n","\n","    x = self.conv2(x)\n","    x = self.bn2(x)\n","    x = F.relu(x)\n","    x = self.dropout(x)\n","\n","    x = self.conv3(x)\n","    x = self.bn3(x)\n","    x = F.relu(x)\n","    x = self.mp(x)\n","    x = self.dropout(x)\n","\n","    x = self.conv4(x)\n","    x = self.bn4(x)\n","    x = F.relu(x)\n","    x = self.dropout(x)\n","\n","    x = self.conv5(x)\n","    x = self.bn5(x)\n","    x = F.relu(x)\n","\n","    x = self.globalmp(x)\n","    x = self.flat(x)\n","    x = self.fc1(x)\n","    \n","    return x"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bySAOl7sZkdS","colab_type":"text"},"source":["## Train & Test"]},{"cell_type":"code","metadata":{"id":"isfxBhMGdKVr","colab_type":"code","colab":{}},"source":["# TRAINING THE NETWORK\n","\n","def train(model, device, train_loader, optimizer, criterion):\n","  model.train()\n","  loss_list = []\n","  outputs = []\n","  targets = []\n","    \n","  for sample_batched in train_loader:\n","    data, target = sample_batched\n","    data = torch.autograd.Variable(data.to(device))\n","    target = torch.autograd.Variable(target.to(device))\n","\n","    output = model(data.float())\n","    loss = criterion(output, target.long())\n","\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    outputs.append(output.detach().numpy().argmax(axis=1))\n","    targets.append(target)\n","    loss_list.append(loss.item())\n","    \n","  loss = np.mean(loss_list)\n","  score = f1_score(np.hstack(targets), np.hstack(outputs), average='macro')\n","  \n","  print('*TRAIN*')\n","  print('Loss:', loss)\n","  print('F1-score:', score)\n","\n","  return loss, score"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QK9wkq_zdYO7","colab_type":"code","colab":{}},"source":["# TESTING THE MODEL\n","\n","def test(model, device, test_loader, criterion):\n","  model.eval()\n","  loss_list = []\n","  outputs = []\n","  targets = []\n","\n","  with torch.no_grad():\n","    for sample_batched in test_loader:\n","      data, target = sample_batched\n","      data = torch.autograd.Variable(data.to(device))\n","      target = torch.autograd.Variable(target.to(device))\n","      \n","      output = model(data.float())\n","      loss = criterion(output, target.long())\n","            \n","      outputs.append(output.detach().numpy().argmax(axis=1))\n","      targets.append(target)\n","      loss_list.append(loss.item())\n","\n","  loss = np.mean(loss_list) \n","  score = f1_score(np.hstack(targets), np.hstack(outputs), average='macro')\n","\n","  print(\"*TEST*\")\n","  print('Loss:', loss)\n","  print('F1-score:', score)\n","\n","  return loss, score"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sOpL3D74OLtv","colab_type":"code","colab":{}},"source":["def prediction(model, val_loader, device):\n","  model.eval()\n","  outputs = []\n","\n","  with torch.no_grad():\n","    for sample_batched in val_loader:\n","      data = sample_batched\n","      data = torch.autograd.Variable(data.to(device))\n","      \n","      output = model(data.float())\n","      outputs.append(output.detach().numpy().argmax(axis=1))\n","\n","  predictions = np.hstack(np.array(outputs))\n","  return predictions"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uqzXIsF5mCAv","colab_type":"code","colab":{}},"source":["def save_predictions(predictions, le):\n","  decoder = le.inverse_transform(y_pred)\n","  forecast = pd.Series(decoder)\n","  df_pred = pd.read_csv('drive/My Drive/Audio analytics/data/sample_submission.csv')\n","  df_pred['label'] = forecast\n","  df_pred.to_csv('drive/My Drive/Audio analytics/data/test.csv', index=None)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dCCo_24fddFg","colab_type":"code","colab":{}},"source":["def plot(train, test, n_epoch, title, ylabel):\n","  epochs = np.arange(1, n_epoch+1)\n","\n","  axes = plt.gca()\n","  axes.set_ylim([0, max(max(train), max(test))])\n","  plt.plot(epochs, train, 'r', label='train')\n","  plt.plot(epochs, test, 'b', label='test')\n","  plt.title(title)\n","  plt.xlabel('epoch number')\n","  plt.ylabel(ylabel)\n","  plt.legend()\n","  plt.grid()\n","  plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"e02pzOPodiLA","colab_type":"code","colab":{}},"source":["criterion = nn.CrossEntropyLoss()\n","model = EffNet()\n","optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","n_epoch = 50\n","\n","train_loss = np.zeros((n_epoch))\n","train_score = np.zeros((n_epoch))\n","test_loss = np.zeros((n_epoch))\n","test_score = np.zeros((n_epoch))\n","best_score = 0.0\n","\n","for e in range(n_epoch):\n","  print(\"*********************************\")\n","  print(\"EPOCH #\", e)\n","  train_loss[e], train_score[e] = train(model, device, train_loader, optimizer, criterion)\n","  test_loss[e], test_score[e] = test(model, device, test_loader, criterion)\n","\n","  if test_score[e] > best_score:\n","    best_score = test_score[e]\n","    torch.save(model.state_dict(), 'drive/My Drive/Audio analytics/convnet.pth')\n","    #torch.save({'epoch': epoch, \n","    #            'model_state_dict': model.state_dict(), \n","    #            'optimizer_state_dict': optimizer.state_dict(), '\n","    #            loss': loss}, 'drive/My Drive/Audio analytics/convnet.pth')\n","\n","plot(train_loss, test_loss, n_epoch, title='Loss', ylabel='loss value')\n","plot(train_score, test_score, n_epoch, title='F1-score', ylabel='f1-score value')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wcSnQpYfjoJF","colab_type":"code","colab":{}},"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","model_dict = torch.load('drive/My Drive/Audio analytics/convnet.pth')\n","model = ConvNet()\n","model.load_state_dict(model_dict)\n","\n","y_pred = prediction(model, val_loader, device)\n","save_predictions(y_pred, le)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cBuO60WyVEn_","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}